import datetime
import logging
import os
import platform
import re
import socket
import subprocess
import tempfile
import time
import uuid
import webbrowser
from ctypes import cast, POINTER
from urllib.request import urlopen

import cv2
import psutil
import pyautogui
import pygetwindow as gw
import requests
from aiogram import Bot, Dispatcher, types, executor
from aiogram.contrib.fsm_storage.memory import MemoryStorage
from aiogram.dispatcher import FSMContext
from aiogram.dispatcher.filters.state import State, StatesGroup
from aiogram.types import CallbackQuery, InlineKeyboardButton, InlineKeyboardMarkup
from aiogram.utils.exceptions import NetworkError
from comtypes import CLSCTX_ALL
from pycaw.api.endpointvolume import IAudioEndpointVolume
from pycaw.utils import AudioUtilities
from screeninfo import get_monitors

from keyboards import keyboard, keyboard_volume, keyboard_media

pyautogui.FAILSAFE = True
pyautogui.PAUSE = 1.5

logging.basicConfig(level=logging.INFO)

token = '5601004463:AAHmEsiVDMxE7fCSCD2-sOE0lMjXZHvqaWg'
bot = Bot(token=token)
dp = Dispatcher(bot=bot, storage=MemoryStorage())


class YourStateEnum(StatesGroup):
    volume = State()


def system_inf():
    time_pc = psutil.boot_time()
    uptime = datetime.datetime.now() - datetime.datetime.fromtimestamp(time_pc)
    uptime_work = str(datetime.timedelta(seconds=round(uptime.total_seconds())))
    info = {
        '–í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã –ü–ö': uptime_work,
        '–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞': platform.system(),
        '–û–ø–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–∞–º—è—Ç—å': psutil.virtual_memory()[0],
        '–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä': platform.processor(),
        '–ú–∞—à–∏–Ω–∞': platform.machine()
    }
    result = ''
    for key, values in info.items():
        result += f'{key}: {values}\n'
    return result


def ip_PC():
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ PC(hostname, IP, MAC)"""
    # –ò–º—è –∫–æ–º–ø—å—é—Ç–µ—Ä–∞
    hostname = socket.gethostname()
    # –ü–æ–ª—É—á–∞–µ–º IP-–∞–¥—Ä–µ—Å
    ip_address = str(urlopen('http://checkip.dyndns.com/')
                     .read())
    # –ü–æ–ª—É—á–∞–µ–º MAC-–∞–¥—Ä–µ—Å
    mac_address = ':'.join(['{:02x}'.format((uuid.getnode() >> i) & 0xff) for i in range(0, 8 * 6, 8)][::-1])
    return "–ò–º—è –∫–æ–º–ø—å—é—Ç–µ—Ä–∞: " + hostname + \
           "\nIP-–∞–¥—Ä–µ—Å: " + re.compile(r'Address: (\d+\.\d+\.\d+\.\d+)').search(ip_address).group(1) + \
           "\nMAC-–∞–¥—Ä–µ—Å: " + mac_address

def browser(url):
    webbrowser.open(url)


def join_classroom():
    """–ü–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ Google Classroom."""
    if '–ö–ú–ü 22-1/11 I –∫—É—Ä—Å II —Å–µ–º.2022-2023 - Google Chrome' in gw.getAllTitles():
        try:
            google_window = gw.getWindowsWithTitle('–ö–ú–ü 22-1/11 I –∫—É—Ä—Å II —Å–µ–º.2022-2023 - Google Chrome')[0]
            google_window.maximize()
            google_window.activate()
            time.sleep(1.5)
            pyautogui.moveTo(x=542, y=526)
            connect = pyautogui.click()
            response = requests.get('https://meet.google.com/kht-cavh-trn?authuser=2')
            if response.status_code == 200:
                time.sleep(1.5)
                off_micro = pyautogui.click(x=684, y=756)
                off_camera = pyautogui.click(x=765, y=759)
                time.sleep(1)
                # con = pyautogui.click(x=1262, y=584)
                return '–í—ã –ø–æ–¥–∫–ª—é—á–µ–Ω—ã'
            else:
                return "–°–∞–π—Ç –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω"
        except ConnectionError:
            return '–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É!'
    else:
        try:
            webbrowser.register('google-chrome', None,
                                webbrowser.BackgroundBrowser('C:\Program Files\Google\Chrome\Application\chrome.exe'))
            webbrowser.get(using='google-chrome').open('https://classroom.google.com/u/2/c/NTgyMDE2NTQ1Nzky?hl=ru')
            time.sleep(1.5)
            pyautogui.moveTo(x=542, y=526)
            connect = pyautogui.click()
            response = requests.get('https://meet.google.com/kht-cavh-trn?authuser=2')
            if response.status_code == 200:
                time.sleep(1.5)
                off_micro = pyautogui.click(x=684, y=756)
                off_camera = pyautogui.click(x=765, y=759)
                time.sleep(1)
                # con = pyautogui.click(x=1262, y=584)
                return '–í—ã –ø–æ–¥–∫–ª—é—á–µ–Ω—ã'
            else:
                return "–°–∞–π—Ç –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω"
        except ConnectionError:
            return '–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É!'


def disconnect_class():
    '''–í—ã—Ö–æ–¥–∏—Ç —Å —É—Ä–æ–∫–∞ –≤ Classroom'''
    pyautogui.moveTo(x=1115, y=1038, duration=0.5)
    pyautogui.click()


def power_off():
    subprocess.call(['shutdown', '/s', '/t', '1'])


def reboot():
    subprocess.call(['shutdown', '/r', '/t', '1'])


def adjust_volume(volume_percent: int):
    """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –≥—Ä–æ–º–∫–æ—Å—Ç—å –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç."""
    if volume_percent != 0:
        direction = 'volumeup' if volume_percent > 0 else 'volumedown'
        pyautogui.press(direction, presses=abs(volume_percent) // 2)
    else:
        pyautogui.press('volumemute')


@dp.message_handler(commands=['start'])
async def welcome_message(message: types.Message):
    try:
        await message.answer(
            '–ü—Ä–∏–≤–µ—Ç. –≠—Ç–æ—Ç –±–æ—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –ü–ö —Å –ø–æ–º–æ—â—å—é Telegram.\n /help –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–æ–º–∞–Ω–¥')
    except ConnectionError:
        await message.answer('–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É!')


@dp.message_handler(commands=['help'])
async def help_command(message: types.Message):
    await message.answer('/systeminfo - –ø–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ü–ö –∫ –∫–æ—Ç–æ—Ä–æ–º—É –≤—ã –ø–æ–¥–∫–ª—é—á–µ–Ω—ã\n'
                         '/ip_pc - –ø–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ü–ö(hostname, IP, MAC)\n', reply_markup=keyboard)


@dp.message_handler(commands=['system'], commands_prefix='üíª')
async def system_command(message: types.Message):
    await message.answer(system_inf())




@dp.message_handler(commands=['ip'])
async def ip_command(message: types.Message):
    await message.answer(ip_PC())


@dp.message_handler(commands=['join'])
async def join_command(message: types.Message):
    await message.answer(join_classroom())


@dp.message_handler(commands=['disconnect'])
async def disconnect_command():
    disconnect_class()


@dp.message_handler(commands=['reboot'])
async def reboot_command(message: types.Message):
    await message.answer('–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –ü–ö...')
    reboot()


@dp.message_handler(commands=['off'])
async def off_command(message: types.Message):
    await message.answer('–í—ã–∫–ª—é—á–µ–Ω–∏–µ...')
    power_off()


@dp.message_handler(commands=['volume'])
async def volume_command(message: types.Message):
    devices = AudioUtilities.GetSpeakers()
    interface = devices.Activate(
        IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
    volume = cast(interface, POINTER(IAudioEndpointVolume))
    await message.answer(f'–¢–µ–∫—É—â–∞—è –≥—Ä–æ–º–∫–æ—Å—Ç—å: {round(volume.GetMasterVolumeLevelScalar() * 100)}%',
                         reply_markup=keyboard_volume)


@dp.message_handler(commands=['media'])
async def media_command(message: types.Message):
    await message.answer('Media', reply_markup=keyboard_media)


@dp.message_handler(commands=['screens'])
async def screens_command(message: types.Message):
    monitors = get_monitors()
    if len(monitors) > 0:
        response = ""
        i = 0
        keyboard_screen = InlineKeyboardMarkup()
        for monitor in monitors:
            button = InlineKeyboardButton(text=f'–°–∫—Ä–∏–Ω—à–æ—Ç —ç–∫—Ä–∞–Ω–∞ ‚Ññ{i} ({monitor.width}x{monitor.height})',
                                          callback_data=f'{i}')
            keyboard_screen.add(button)
            response += f"‚Ññ{i}: {monitor.width}x{monitor.height}. –ê–∫—Ç–∏–≤–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä: {monitor.is_primary}\n"
            i += 1
        await message.answer(f'–°–ø–∏—Å–æ–∫ —ç–∫—Ä–∞–Ω–æ–≤ ({len(monitors)}):\n'
                             f'{response}', reply_markup=keyboard_screen)
    else:
        await message.answer("–ú–æ–Ω–∏—Ç–æ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω")


@dp.message_handler(commands=['cameras'])
async def cameras_command(message: types.Message):
    cap = cv2.VideoCapture(0)

    if not cap.isOpened():
        await message.answer('–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É')
        exit()
    ret, frame = cap.read()
    with tempfile.NamedTemporaryFile(suffix='.jpg', dir=tempfile.gettempdir(), delete=False) as temp_file:
        cv2.imwrite(temp_file.name, frame)
        cap.release()
        temp_file.seek(0)
        if os.path.exists(temp_file.name):
            await bot.send_photo(message.chat.id, open(temp_file.name, 'rb'))
            temp_file.close()
            os.unlink(temp_file.name)


@dp.callback_query_handler(lambda callback_query: callback_query.data and callback_query.data.isdigit())
async def handle_monitor_screen(callback_query: types.CallbackQuery):
    screen_number = int(callback_query.data)
    screen = pyautogui.screenshot()
    with tempfile.NamedTemporaryFile(suffix='.jpeg', dir=tempfile.gettempdir(), delete=False) as temp_file:
        screen.save(temp_file.name)
        temp_file.seek(0)
        if os.path.exists(temp_file.name):
            await bot.send_photo(callback_query.message.chat.id, open(temp_file.name, 'rb'))
            temp_file.close()
            os.unlink(temp_file.name)
        else:
            await callback_query.answer('–û—à–∏–±–∫–∞: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω')


@dp.callback_query_handler(lambda callback_query: callback_query.data == 'btn_volume')
async def volume_handler(callback_query: CallbackQuery, state: FSMContext):
    await callback_query.bot.edit_message_text(text='–ù–∞ —Å–∫–æ–ª—å–∫–æ —É–≤–µ–ª–∏—á–∏—Ç—å(+)/—É–º–µ–Ω—å—à–∏—Ç—å(-) –∑–≤—É–∫?',
                                               chat_id=callback_query.from_user.id,
                                               message_id=callback_query.message.message_id)
    await YourStateEnum.volume.set()


@dp.message_handler(state=YourStateEnum.volume, content_types=types.ContentTypes.TEXT)
async def handle_volume(message: types.Message, state: FSMContext):
    devices = AudioUtilities.GetSpeakers()
    interface = devices.Activate(
        IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
    volume = cast(interface, POINTER(IAudioEndpointVolume))
    current_value = round(volume.GetMasterVolumeLevelScalar() * 100)
    value = int(message.text)
    adjust_volume(value)
    if value > 0:
        await message.answer(f"–ì—Ä–æ–º–∫–æ—Å—Ç—å —É–≤–µ–ª–∏—á–µ–Ω–∞ –¥–æ {current_value + value}%")
    else:
        await message.answer(f'–ì—Ä–æ–º–∫–æ—Å—Ç—å –ø–æ–Ω–∏–∂–µ–Ω–∞ –¥–æ {current_value + value}%')
    await state.reset_state()


@dp.callback_query_handler(lambda callback_query: callback_query.data == 'mute')
async def mute_volume(message: types.Message):
    adjust_volume(0)


@dp.callback_query_handler(lambda callback_query: CallbackQuery)
async def media_controller(callback_query: CallbackQuery):
    if callback_query.data == 'btn_next':
        pyautogui.press('nexttrack')
    elif callback_query.data == 'btn_stop':
        pyautogui.press('playpause')
    elif callback_query.data == 'btn_back':
        pyautogui.press('prevtrack', presses=2)

@dp.message_handler(content_types=['text'])
async def browser_open_url(message: types.Message):
    browser(url=message.text)
    await message.answer('–°–∞–π—Ç –æ—Ç–∫—Ä—ã—Ç')


if __name__ == '__main__':
    while True:
        try:
            executor.start_polling(dp, skip_updates=True)
        except NetworkError:
            time.sleep(3)
            print('Error')
